# 做项目中遇到的问题或者想到的想法随手一记

## 后端

### 每一个模块创建一个枚举类

最好每一个模块创建一个枚举类，或者多个枚举类，按业务类型分开。例如：异常枚举类，枚举中可以定义错误码和错误描述

### 代码中的常量使用常量类

代码中出现的常量要定义到常量类中，如果只涉及本类使用的可以定义成类全局常量。

一般每一个模块一个常量类

命名规则：xxxConsts

### 在controller 可以使用的方法

批量修改

例如：

```
ControllerUtil.batchUpdateByIds(ids, PayOrderConsts.PAY_ORDER_RISK_STATE, organizationPayOrderService::batchUpdateState);
```

单个操作：

```
ControllerUtil.operationResult()
```

### 实体命名说明

查询实体类命名为：XXXQuery

数据传输给后台命名为：xxxDTO

从后台传输数据给前台命名为：xxxVO

#### MQ比较

| 特性       | ActiveMQ                               | RabbitMQ                   | RocketMQ                 | Kafka                                    |
| ---------- | -------------------------------------- | -------------------------- | ------------------------ | ---------------------------------------- |
| 开发语言   | java                                   | erlang                     | java                     | scala                                    |
| 单机吞吐量 | 万级                                   | 万级                       | 10万级                   | 100万级                                  |
| 时效性     | ms                                     | us                         | ms                       | ms                                       |
| 可用性     | 高（主从）                             | 高（主从）                 | 非常高（分布式）         | 非常高（分布式）                         |
| 功能特性   | 成熟的产品、较全的文档、各种协议支持好 | 并发能力强、性能好、延迟低 | MQ功能比较完善，扩展性佳 | 只支持主要的MQ功能，主要应用于大数据领域 |
|            |                                        |                            |                          |                                          |

| 消息中间件 | 建议                                                         |
| ---------- | ------------------------------------------------------------ |
| Kafka      | 追求高吞吐量，适合产生大量数据的互联网服务的数据收集业务     |
| RocketMQ   | 可靠性要求很高的金融互联网领域,稳定性高，经历了多次阿里双11考验 |
| RabbitMQ   | 性能较好，社区活跃度高，数据量没有那么大，优先选择功能比较完备的RabbitMQ |

#### Kafka动态监听Topic，用在Topic比较多的情况下，并且Topic是存储在数据库或者文件中的

``````java
public static void consumerTest(){
        Properties props = new Properties();
        props.setProperty("bootstrap.servers", "IP:9092");
        props.setProperty("group.id", "test");
        props.setProperty("enable.auto.commit", "true");//设置enable.auto.commit意味着自动提交偏移量，其频率由配auto.commit.interval.ms控制
        props.setProperty("auto.commit.interval.ms", "1000");
        props.setProperty("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.setProperty("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);

        /**
         * 消费订阅哪一个topic或者哪几个topic
         *   我这里：消费者订阅了主题susu-topic和susu-topic-2，作为消费者组test的一部分，并配置了group.id。
         */
        consumer.subscribe(Arrays.asList("susu-topic", "susu-topic-2"));

        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));//每100毫秒拉取一次
            for (ConsumerRecord<String, String> record : records)
                System.out.printf("topic = %s,partition = %d, offset = %d, key = %s, value = %s%n",
                        record.topic(),record.partition(),record.offset(), record.key(), record.value());
        }
    }

    public static void main(String[] args) {
        consumerTest();
    }
``````



## 前端

